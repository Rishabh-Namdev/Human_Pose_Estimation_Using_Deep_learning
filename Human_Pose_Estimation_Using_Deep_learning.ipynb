{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjhwBI9z1LVH"
      },
      "source": [
        "# Setting the environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn_5GVz-o6BH",
        "outputId": "b53ff042-316b-4683-90a9-645e84af3836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/lightweight-human-pose-estimation.pytorch\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "FOLDERNAME = 'lightweight-human-pose-estimation.pytorch'\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UruS4OOjpwQY"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2htOUqQ0bJR"
      },
      "source": [
        "# Downloading openvino\n",
        "This will take around 15 mins to download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pysLu0580Zds"
      },
      "outputs": [],
      "source": [
        "!pip install openvino-colab\n",
        "!pip install openvino\n",
        "import openvino_colab #choose 5 generally, this step generally takes some time\n",
        "install_dir = \"/opt/intel/openvino_2021/\"\n",
        "model_optimizer = '/opt/intel/openvino_2021/deployment_tools/model_optimizer/'\n",
        "deployment_tools = '/opt/intel/openvino_2021/deployment_tools/'\n",
        "model_zoo = '/opt/intel/openvino_2021/deployment_tools/open_model_zoo/'\n",
        "!python $model_zoo'tools/downloader/'downloader.py --name vehicle-attributes-recognition-barrier-0039 --precisions FP32 -o /content/openvino-colab/demo_files/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY37VjJq0n4P"
      },
      "outputs": [],
      "source": [
        "from openvino.inference_engine import IENetwork\n",
        "from openvino.inference_engine import IECore\n",
        "import warnings\n",
        "from google.colab.patches import cv2_imshow\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def load_IR_to_IE(model_xml):\n",
        "    ### Load the Inference Engine API\n",
        "    plugin = IECore()\n",
        "    ### Loading the IR files to IENetwork class\n",
        "    model_bin = model_xml[:-3]+\"bin\"\n",
        "    network = IENetwork(model=model_xml, weights=model_bin)\n",
        "    ### Loading the network\n",
        "    executable_net = plugin.load_network(network,\"CPU\")\n",
        "    print(\"Network succesfully loaded into the Inference Engine\")\n",
        "    return executable_net\n",
        "\n",
        "def synchronous_inference(executable_net, image):\n",
        "    ### Get the input blob for the inference request\n",
        "    input_blob = next(iter(executable_net.inputs))\n",
        "    ### Perform Synchronous Inference\n",
        "    result = executable_net.infer(inputs = {input_blob: image})\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI5-EIsn0NfL"
      },
      "source": [
        "# Converting into onnx file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBjxSk3MrW-p"
      },
      "outputs": [],
      "source": [
        "!python scripts/convert_to_onnx.py --checkpoint-path checkpoint_iter_370000.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TVZSDor0spV"
      },
      "source": [
        "# Using vino to optimize to real time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a3N8av9KEQZ"
      },
      "outputs": [],
      "source": [
        "!python $model_optimizer''/mo.py --input_model human-pose-estimation.onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdT1Pw1Qz5wg"
      },
      "source": [
        "# Testing the model on an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTERpAkLqTHE"
      },
      "outputs": [],
      "source": [
        "!python demo.py --checkpoint-path checkpoint_iter_370000.pth --image '/content/drive/MyDrive/lightweight-human-pose-estimation.pytorch/test.jpg'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gvl8dmu0AGI"
      },
      "source": [
        "# Testing the model on a video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "nwjCAsV2jjX1"
      },
      "outputs": [],
      "source": [
        "!python demo.py --checkpoint-path checkpoint_iter_370000.pth --video '/content/drive/MyDrive/lightweight-human-pose-estimation.pytorch/test.mp4'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o_615aD0Ciu"
      },
      "source": [
        "# Saving the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a933AvoqUEUK",
        "outputId": "0f6d7713-4060-4cb5-f7f7-b8ca804054ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to rishi.mp4\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Path to the folder containing images\n",
        "image_folder = 'test'\n",
        "\n",
        "# Output video file name and properties\n",
        "output_video_path = 'rishi.mp4'\n",
        "fps = 30.0  # Frames per second\n",
        "\n",
        "# Get the list of image files in the folder\n",
        "image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Read the dimensions of the first image to set up the VideoWriter\n",
        "first_image = cv2.imread(image_files[0])\n",
        "height, width, layers = first_image.shape\n",
        "\n",
        "# Create a VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can try other codecs as well\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# Iterate through the list of images and write each frame to the video\n",
        "for image_file in image_files:\n",
        "    img = cv2.imread(image_file)\n",
        "    out.write(img)\n",
        "\n",
        "# Release the VideoWriter object\n",
        "out.release()\n",
        "\n",
        "print(f\"Video saved to {output_video_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
